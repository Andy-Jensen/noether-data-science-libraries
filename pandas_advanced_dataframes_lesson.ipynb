{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607c79fe",
   "metadata": {},
   "source": [
    "# Advanced Dataframes\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. Part I: Creating Dataframes\n",
    "    - from Lists, Arrays, & Dictionaries\n",
    "    - from PyDataset\n",
    "    - from a SQL query\n",
    "2. Exercises, Part I\n",
    "3. Part II\n",
    "    - Indexing and Subsetting\n",
    "    - Aggregating\n",
    "    - Merging & Joining\n",
    "4. Exercises, Part II\n",
    "5. Part III: Reshaping & Transposing\n",
    "    - Reshaping\n",
    "    - Transposing\n",
    "10. Exercises III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbab02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97dceb7",
   "metadata": {},
   "source": [
    "## Part I: Creating Dataframes\n",
    "\n",
    "### From Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00693f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9154978",
   "metadata": {},
   "source": [
    "### From Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac338c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1e2dc61",
   "metadata": {},
   "source": [
    "### From Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a95b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4688a0",
   "metadata": {},
   "source": [
    "### From PyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47212d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bc6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade8f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcadaef5",
   "metadata": {},
   "source": [
    "### From SQL\n",
    "\n",
    "We can use the read_sql method to create a dataframe based on the results of a SQL query. To do this, we need to tell pandas how to connect to the database we are querying. The way we communicate this to pandas is with a specially formatted connection string.\n",
    "\n",
    "In addition, whenever we want to connect to a database from our python code (other programming languages are similar), we will need a driver, a bit of software that handles the details of the database connection.\n",
    "\n",
    "1. In order to connect to mysql, we'll install the pymysql driver packages by typing the following in your terminal: `python -m pip install pymysql'\n",
    "1. **Add env.py to the repo's .gitignore file**\n",
    "2. create a text file called env.py, and in your text file, write the following (filling in the corresponding info):\n",
    "\n",
    "```python\n",
    "host = '<ip_address>'\n",
    "username = '<your_username>'\n",
    "password = '<your_password>'\n",
    "```\n",
    "\n",
    "4. import the host, username, and password variables from the env.py file. Note that upon import, you use `env`, not `env.py`. **once you assign the string to the variable `url`, DO NOT print the value of url to your notebook. If you do this and push the notebook to github, your username and password will be visible to others.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45b827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the url variable (string) with my username, password and host inserted\n",
    "from env import host, username, password\n",
    "url = f'mysql+pymysql://{username}:{password}@{host}/employees'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d989edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the SQL query to gather data, assign to variable 'query'\n",
    "query = 'SELECT * FROM employees LIMIT 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d93290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data passing the function the query and the url string\n",
    "df = pd.read_sql(query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb73937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_no</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1953-09-02</td>\n",
       "      <td>Georgi</td>\n",
       "      <td>Facello</td>\n",
       "      <td>M</td>\n",
       "      <td>1986-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1964-06-02</td>\n",
       "      <td>Bezalel</td>\n",
       "      <td>Simmel</td>\n",
       "      <td>F</td>\n",
       "      <td>1985-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>1959-12-03</td>\n",
       "      <td>Parto</td>\n",
       "      <td>Bamford</td>\n",
       "      <td>M</td>\n",
       "      <td>1986-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>1954-05-01</td>\n",
       "      <td>Chirstian</td>\n",
       "      <td>Koblick</td>\n",
       "      <td>M</td>\n",
       "      <td>1986-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>1955-01-21</td>\n",
       "      <td>Kyoichi</td>\n",
       "      <td>Maliniak</td>\n",
       "      <td>M</td>\n",
       "      <td>1989-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10006</td>\n",
       "      <td>1953-04-20</td>\n",
       "      <td>Anneke</td>\n",
       "      <td>Preusig</td>\n",
       "      <td>F</td>\n",
       "      <td>1989-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10007</td>\n",
       "      <td>1957-05-23</td>\n",
       "      <td>Tzvetan</td>\n",
       "      <td>Zielinski</td>\n",
       "      <td>F</td>\n",
       "      <td>1989-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10008</td>\n",
       "      <td>1958-02-19</td>\n",
       "      <td>Saniya</td>\n",
       "      <td>Kalloufi</td>\n",
       "      <td>M</td>\n",
       "      <td>1994-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10009</td>\n",
       "      <td>1952-04-19</td>\n",
       "      <td>Sumant</td>\n",
       "      <td>Peac</td>\n",
       "      <td>F</td>\n",
       "      <td>1985-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10010</td>\n",
       "      <td>1963-06-01</td>\n",
       "      <td>Duangkaew</td>\n",
       "      <td>Piveteau</td>\n",
       "      <td>F</td>\n",
       "      <td>1989-08-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_no  birth_date first_name  last_name gender   hire_date\n",
       "0   10001  1953-09-02     Georgi    Facello      M  1986-06-26\n",
       "1   10002  1964-06-02    Bezalel     Simmel      F  1985-11-21\n",
       "2   10003  1959-12-03      Parto    Bamford      M  1986-08-28\n",
       "3   10004  1954-05-01  Chirstian    Koblick      M  1986-12-01\n",
       "4   10005  1955-01-21    Kyoichi   Maliniak      M  1989-09-12\n",
       "5   10006  1953-04-20     Anneke    Preusig      F  1989-06-02\n",
       "6   10007  1957-05-23    Tzvetan  Zielinski      F  1989-02-10\n",
       "7   10008  1958-02-19     Saniya   Kalloufi      M  1994-09-15\n",
       "8   10009  1952-04-19     Sumant       Peac      F  1985-02-18\n",
       "9   10010  1963-06-01  Duangkaew   Piveteau      F  1989-08-24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "add1bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a query in multiple lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42dfb806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_no</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>Bezalel</td>\n",
       "      <td>Simmel</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>Anneke</td>\n",
       "      <td>Preusig</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>Tzvetan</td>\n",
       "      <td>Zielinski</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10009</td>\n",
       "      <td>Sumant</td>\n",
       "      <td>Peac</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010</td>\n",
       "      <td>Duangkaew</td>\n",
       "      <td>Piveteau</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_no first_name  last_name gender\n",
       "0   10002    Bezalel     Simmel      F\n",
       "1   10006     Anneke    Preusig      F\n",
       "2   10007    Tzvetan  Zielinski      F\n",
       "3   10009     Sumant       Peac      F\n",
       "4   10010  Duangkaew   Piveteau      F"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT emp_no, first_name, last_name, gender\n",
    "FROM employees\n",
    "WHERE gender = 'F'\n",
    "LIMIT 100;\n",
    "'''\n",
    "\n",
    "employees_df = pd.read_sql(query, url)\n",
    "employees_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21079f7c",
   "metadata": {},
   "source": [
    "## Exercises, Part I\n",
    "\n",
    "Create a notebook or python script named `advanced_dataframes` to do your work in for these exercises.\n",
    "\n",
    "1. Run python -m pip install pymysql from your terminal to install the mysql client (any folder is fine)\n",
    "\n",
    "2. cd into your exercises folder for this module and run echo env.py >> .gitignore\n",
    "\n",
    "3. Create a function named get_db_url. It should accept a username, hostname, password, and database name and return a url connection string formatted like in the example at the start of this lesson.\n",
    "\n",
    "4. Use your function to obtain a connection to the employees database.\n",
    "\n",
    "5. Once you have successfully run a query:\n",
    "    - Intentionally make a typo in the database url. What kind of error message do you see?\n",
    "    - Intentionally make an error in your SQL query. What does the error message look like?\n",
    "\n",
    "\n",
    "6. Read the employees and titles tables into two separate DataFrames.\n",
    "\n",
    "7. How many rows and columns do you have in each DataFrame? Is that what you expected?\n",
    "\n",
    "8. Display the summary statistics for each DataFrame.\n",
    "\n",
    "9. How many unique titles are in the titles DataFrame?\n",
    "\n",
    "10. What is the oldest date in the to_date column?\n",
    "\n",
    "11. What is the most recent date in the to_date column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f3977",
   "metadata": {},
   "source": [
    "## Part II\n",
    "\n",
    "### Indexing and Subsetting\n",
    "\n",
    "- `[]`: subset rows using a boolean mask, or subset columns using a list of column names. \n",
    "- `.loc`: allows for subsetting rows and columns simultaneously, using the labels/names of rows/columns. \n",
    "- `.iloc`: allows for subsetting rows and columns simultaneously, using the index location or position of rows/columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50252ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21489a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of values for names column.\n",
    "names = ['Sally', 'Jane', 'Suzie', 'Billy', 'Ada', 'John', 'Thomas', 'Marie', 'Albert', 'Richard', 'Isaac', 'Alan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef9f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate arrays of scores for each student for each subject.\n",
    "# Note that all the values need to have the same length here.\n",
    "\n",
    "math_grades = np.random.randint(low = 60, high = 101, size = len(names))\n",
    "english_grades = np.random.randint(low = 60, high = 101, size = len(names))\n",
    "reading_grades = np.random.randint(low = 60, high = 101, size = len(names))\n",
    "\n",
    "classroom = np.random.choice(['A', 'B']), len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca71262",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Construct the DataFrame using the above lists and arrays.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath_grades\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_grades\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreading\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreading_grades\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassroom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassroom\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Construct the DataFrame using the above lists and arrays.\n",
    "\n",
    "df = pd.DataFrame({'names': names,\n",
    "                  'math': math_grades,\n",
    "                  'english': english_grades,\n",
    "                  'reading': reading_grades,\n",
    "                  'classroom': classroom\n",
    "                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25c610",
   "metadata": {},
   "source": [
    "Bracket: `[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0ab306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 2 columns from the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85ca1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can pass a boolean Series to the indexing operator as a selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba7930a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then subset using brackets with the boolean series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e380794",
   "metadata": {},
   "source": [
    "`.loc`\n",
    "\n",
    "- Select specific rows AND columns by index **label**. \n",
    "- The index label can be a number, but it can also be a string label. \n",
    "- It is **inclusive.**\n",
    "\n",
    "`df.loc[row_indexer, column_indexer]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50bfee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the rows and a subset of columns; \n",
    "# notice the inclusive behavior of the indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c568a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use a boolean Series as a selector with .loc, too, \n",
    "# but I can choose rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7490c5c",
   "metadata": {},
   "source": [
    "`.iloc`\n",
    "\n",
    "- Select specific rows and colums by index **position**. \n",
    "- It does **not** accept a boolean Series as a selector like .loc does. \n",
    "- It takes in integers representing index position\n",
    "- It is **exclusive**.\n",
    "\n",
    "`df.iloc[row_indexer, column_indexer]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d80f4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows by integer position\n",
    "# notice the exclusive behavior of the indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e401897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53fe4a91",
   "metadata": {},
   "source": [
    "### Aggregating\n",
    "\n",
    "`.agg`\n",
    "\n",
    "- Specify a way to aggregate a series of numerical values. \n",
    "- We pass an aggregate function or list of functions to the method that we want applied to a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21b799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5586bdbf",
   "metadata": {},
   "source": [
    "What happens if you run it on the entire dataframe, not just a series of a single column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "640c2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate each column in the dataframe by taking the min value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41245db",
   "metadata": {},
   "source": [
    "While on the surface this seems pretty simple, `.agg` is capable of providing more detailed aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4dd3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343f53e1",
   "metadata": {},
   "source": [
    "`groupby`\n",
    "\n",
    "- Creates a grouped object. \n",
    "- Then apply an aggregation on that object. \n",
    "\n",
    "For example, if we wanted to know the highest math grade from each classroom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54474ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52263dcc",
   "metadata": {},
   "source": [
    "We can use `.agg` here to, to see multiple aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c58cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b3803e0",
   "metadata": {},
   "source": [
    "We can group by multiple columns as well. \n",
    "\n",
    "Let's compute the average reading grade for students who are passing english and those who are not passing english. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3349ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean column named passing_english \n",
    "# based on the math column using np.where\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02760c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the combination of our new feature, passing_english,\n",
    "# and the classroom.\n",
    "# aggregate by calculating average reading grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b52706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the column names to make the data more transparent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b909f",
   "metadata": {},
   "source": [
    "`.transform`\n",
    "\n",
    "When you want to add an aggregate value, like the average math grades for each classroom, back to the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582e10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "127f3965",
   "metadata": {},
   "source": [
    "`.describe` \n",
    "\n",
    "Can be used with `groupby` also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c57ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6074be",
   "metadata": {},
   "source": [
    "### Merging & Joining\n",
    "\n",
    "Ways to combine dataframes together\n",
    "\n",
    "`pd.concat`\n",
    "\n",
    "- This function takes in a list or dictionary of Series or DataFrame objects and joins them along a particular axis\n",
    "- Row-wise: axis=0, means your new data frame will be longer with more rows. \n",
    "- Column-wise: axis=1, means your new dataframe will be wider with more columns. \n",
    "- When your list contains at least one DataFrame, a DataFrame is returned.\n",
    "- When concatenating only Series objects row-wise, axis=0, a Series is returned.\n",
    "- When concatenating Series or DataFrames column-wise, axis=1, a DataFrame is returned.\n",
    "\n",
    "default parameters: \n",
    "\n",
    "`pd.concat(objs_in_list, axis=0, join='outer')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "15c01e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate 2 dataframes by passing a list of the 2 dfs, and \n",
    "# indicating whether to concatenate along the rows or the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04889ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f2da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4690cfc",
   "metadata": {},
   "source": [
    "**Note** the indices are preserved on the resulting dataframe; we could set the `ignore_index` parameter to True if we wanted these to be sequential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73089792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb371b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e76fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18474902",
   "metadata": {},
   "source": [
    "`.merge`\n",
    "\n",
    "- Similar to a SQL join.\n",
    "- first dataframe is the 'left' table. \n",
    "- `how`: Type of merge to be performed.\n",
    "    - `how=left`: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "    - `how=right`: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "    - `how=outer`: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "    - `how=inner`: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "947a8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the users DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18baec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roles DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a65b5",
   "metadata": {},
   "source": [
    "- `left_on` and `right_on`: indicate the columns that are the keys used to merge the dataframes together.\n",
    "\n",
    "- `indicator`=`True` will create a column indicating whether the merge key appears in the `left_only`, `right_only` or `both` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1b0bce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an outer join specifying the left and right DataFrame keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73185555",
   "metadata": {},
   "source": [
    "- suffix of `_x` to any columns in the left dataframe that are duplicated, \n",
    "- suffix of `_y` to any columns in the right dataframe that are duplicated. \n",
    "- can clean up column names using **method chaining**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcba860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c573f449",
   "metadata": {},
   "source": [
    "## Part 3: Reshaping and Transposing\n",
    "\n",
    "1. Reshaping: pd.crosstab, .pivot_table\n",
    "2. Transposing\n",
    "\n",
    "### Reshaping\n",
    "\n",
    "`pd.crosstab`\n",
    "\n",
    "Count the number of students passing math in each classroom (student grades df):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81bb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3de8877",
   "metadata": {},
   "source": [
    "Add subtotals using the `margins` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb173bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9155cd4",
   "metadata": {},
   "source": [
    "View percentages instead of actual values using the `normalize` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d28b57c5",
   "metadata": {},
   "source": [
    "`.pivot_table`\n",
    "\n",
    "Like an excel pivot table\n",
    "\n",
    "Supply 4 pieces of info to arguments: \n",
    "- which values will make up the rows, the `index`\n",
    "- which values will make up the columns\n",
    "- the values we are aggregating\n",
    "- an aggregation method (`aggfunc`) (default is `mean`). \n",
    "\n",
    "Example: Calculate the average math grade for the combination of `classroom` and `passing_math` status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b2bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51419803",
   "metadata": {},
   "source": [
    "Create a new dataframe: orders at a restaurant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693f048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52dec345",
   "metadata": {},
   "source": [
    "`.map`\n",
    "\n",
    "Use a dictionary to calculate the total price for an order. Then save the calculations to a new column named `bill`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f464b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of prices for drinks and meals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8cca59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the values in the drink and meal columns with the values \n",
    "# in the prices and perform the specificied calculations. \n",
    "# save to a new column, bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b8fb78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use crosstab to look at how many orders have each combination of\n",
    "# meal and drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5096043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the average bill for each combination using pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "211f9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the average bill for each combination using groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bd869",
   "metadata": {},
   "source": [
    "Transposing\n",
    "\n",
    "Swapping rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99e5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
